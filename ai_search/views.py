import json
import requests
import markdown
from django.http import JsonResponse
from django.shortcuts import render
from django.template.loader import render_to_string
from projects.models import Project

# --- Tech Name Mapping ---
TECH_MAP = {
    'íŒŒì´ì¬': 'python', 'python': 'python',
    'ì¥ê³ ': 'django', 'django': 'django',
    'ë¦¬ì•¡íŠ¸': 'react', 'react': 'react',
    'ë„ì»¤': 'docker', 'docker': 'docker',
    'ìë°”ìŠ¤í¬ë¦½íŠ¸': 'javascript', 'javascript': 'javascript',
    'ìë°”': 'java', 'java': 'java',
    'mysql': 'mysql',
    'postgresql': 'postgresql',
}

def ai_search_view(request):
    """
    Renders the main AI chat interface page.
    """
    return render(request, 'ai_search/ai_search.html', {'hide_layout_elements': True})

def chat_interaction(request):
    """
    Handles conversational AJAX requests, integrating session-based context memory,
    interactive project filtering, and LLM fallback.
    """
    if request.method == 'POST':
        try:
            history = request.session.get('chat_history', [])
            data = json.loads(request.body)
            user_message = data.get('message', '').lower().strip()
            ai_response = {}
            simplified_ai_text = ''

            # 1. Analyze user message for tech keywords using TECH_MAP
            detected_techs = list(set([TECH_MAP[key] for key in TECH_MAP if key in user_message]))
            
            last_ai_response_text = history[-1]['ai'] if history else ''
            is_project_context = '[í”„ë¡œì íŠ¸]' in last_ai_response_text

            # 3. Determine action
            # Get all distinct technologies from visible projects for dynamic suggestions
            available_techs_in_visible_projects = set()
            for project in Project.objects.filter(is_visible=True):
                for tech_raw in project.technologies.split(','):
                    tech_en = tech_raw.strip().lower()
                    if tech_en in TECH_MAP.values(): # Check if it's a known tech
                        available_techs_in_visible_projects.add(tech_en)

            dynamic_project_suggestions = []
            if 'ëª¨ë“  í”„ë¡œì íŠ¸ ë³´ê¸°' not in user_message: # Avoid adding if user explicitly asked for all
                dynamic_project_suggestions.append('ëª¨ë“  í”„ë¡œì íŠ¸ ë³´ê¸°')
            
            # Map back to Korean for display
            for tech_en in sorted(list(available_techs_in_visible_projects)):
                # Find the Korean name if available, otherwise use English
                # Prioritize Korean key if it maps to the tech_en
                tech_display = next((k for k, v in TECH_MAP.items() if v == tech_en and k != v), tech_en)
                dynamic_project_suggestions.append(f"{tech_display.capitalize()} í”„ë¡œì íŠ¸ë§Œ ë³´ê¸°")


            # Priority 1: Follow-up filtering
            if detected_techs and is_project_context:
                tech_to_filter = detected_techs[0]
                projects = Project.objects.filter(is_visible=True, technologies__iregex=fr'\b{tech_to_filter}\b').order_by('-created_at')
                if projects.exists():
                    ai_response = {'type': 'html', 'content': render_to_string('ai_search/_project_cards.html', {'projects': projects})}
                    ai_response['suggestions'] = dynamic_project_suggestions
                    simplified_ai_text = f"[{tech_to_filter} í”„ë¡œì íŠ¸ ëª©ë¡ í‘œì‹œ]"
                else:
                    ai_response = {'type': 'text', 'content': f"'{tech_to_filter}' ê¸°ìˆ ì„ í¬í•¨í•˜ëŠ” í”„ë¡œì íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
            
            # Priority 2: Initial project request (with optional filter)
            elif 'í”„ë¡œì íŠ¸' in user_message:
                projects_query = Project.objects.filter(is_visible=True)
                if detected_techs:
                    tech_to_filter = detected_techs[0]
                    projects = projects_query.filter(technologies__iregex=fr'\b{tech_to_filter}\b').order_by('-created_at')
                    if projects.exists():
                        ai_response = {'type': 'html', 'content': render_to_string('ai_search/_project_cards.html', {'projects': projects})}
                        ai_response['suggestions'] = dynamic_project_suggestions
                        simplified_ai_text = f'[{tech_to_filter} í”„ë¡œì íŠ¸ ëª©ë¡ í‘œì‹œ]'
                    else:
                        ai_response = {'type': 'text', 'content': f"'{tech_to_filter}' ê¸°ìˆ ì„ ì‚¬ìš©í•˜ëŠ” í”„ë¡œì íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
                else:
                    projects = projects_query.order_by('-created_at')
                    if projects.exists():
                        ai_response = {'type': 'html', 'content': render_to_string('ai_search/_project_cards.html', {'projects': projects})}
                        ai_response['suggestions'] = dynamic_project_suggestions
                        simplified_ai_text = '[í”„ë¡œì íŠ¸ ëª©ë¡ í‘œì‹œ]'
                    else:
                        ai_response = {'type': 'text', 'content': 'í˜„ì¬ ë°ì´í„°ë² ì´ìŠ¤ì— ë“±ë¡ëœ í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.'}

            # Priority 3: Other keywords
            elif 'ê¸°ìˆ ' in user_message or 'ìŠ¤íƒ' in user_message:
                ai_response = {
                    'type': 'html',
                    'content': """
                    <p>í¬íŠ¸í´ë¦¬ì˜¤ì˜ ì£¼ìš” ê¸°ìˆ  ìŠ¤íƒì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. ğŸ’»</p>
                    <ul>
                        <li><strong>Python &amp; Django:</strong> ì•ˆì •ì ì¸ ë°±ì—”ë“œ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•©ë‹ˆë‹¤.</li>
                        <li><strong>JavaScript &amp; React:</strong> ë™ì ì´ê³  ì¸í„°ë™í‹°ë¸Œí•œ í”„ë¡ íŠ¸ì—”ë“œë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.</li>
                        <li><strong>Docker:</strong> ê°œë°œ ë° ë°°í¬ í™˜ê²½ì˜ ì¼ê´€ì„±ì„ ìœ ì§€í•˜ê³  ìš´ì˜ íš¨ìœ¨ì„±ì„ ë†’ì…ë‹ˆë‹¤.</li>
                        <li><strong>Databases:</strong> PostgreSQL, MySQL ë“± ê´€ê³„í˜• ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ë‹¤ë£¹ë‹ˆë‹¤.</li>
                        <li><strong>Cloud:</strong> AWS, Google Cloud ë“± í´ë¼ìš°ë“œ ì¸í”„ë¼ í™œìš© ê²½í—˜ì´ ìˆìŠµë‹ˆë‹¤.</li>
                    </ul>
                    """,
                    'suggestions': ['ê´€ë ¨ í”„ë¡œì íŠ¸ ë³´ì—¬ì¤˜']
                }
                simplified_ai_text = '[ê¸°ìˆ  ìŠ¤íƒ í‘œì‹œ]'
            
            elif 'ì†Œê°œ' in user_message or 'ë„ˆ' in user_message or 'ëˆ„êµ¬' in user_message or 'ë­˜í• ìˆ˜ìˆ' in user_message or 'ë¬´ì—‡ì„ í• ìˆ˜ìˆ' in user_message:
                ai_response = {
                    'type': 'html',
                    'content': """
                    <p>ì €ëŠ” ì´ í¬íŠ¸í´ë¦¬ì˜¤ì˜ ì£¼ì¸ì— ëŒ€í•´ ì•Œë ¤ì£¼ê¸° ìœ„í•´ ë§Œë“¤ì–´ì§„ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì œê°€ í•  ìˆ˜ ìˆëŠ” ì¼ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:</p>
                    <ul>
                        <li><strong>í”„ë¡œì íŠ¸ ì •ë³´ ì œê³µ:</strong> "í”„ë¡œì íŠ¸ ë³´ì—¬ì¤˜"ë¼ê³  ì…ë ¥í•˜ì‹œë©´ ì£¼ì¸ì˜ í¬íŠ¸í´ë¦¬ì˜¤ í”„ë¡œì íŠ¸ë“¤ì„ ìƒì„¸íˆ ë³´ì—¬ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</li>
                        <li><strong>ê¸°ìˆ  ìŠ¤íƒ ì„¤ëª…:</strong> "ê¸°ìˆ " ë˜ëŠ” "ìŠ¤íƒ"ì— ëŒ€í•´ ë¬¼ì–´ë³´ì‹œë©´ ì£¼ì¸ì´ ì£¼ë¡œ ì‚¬ìš©í•˜ëŠ” ê¸°ìˆ  ìŠ¤íƒì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.</li>
                        <li><strong>ì¼ë°˜ì ì¸ ëŒ€í™”:</strong> í¬íŠ¸í´ë¦¬ì˜¤ì™€ ê´€ë ¨í•˜ì—¬ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë‹¤ë©´ ììœ ë¡­ê²Œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”. ì œê°€ ì•„ëŠ” ë²”ìœ„ ë‚´ì—ì„œ ì„±ì‹¬ê» ë‹µë³€í•´ ë“œë¦½ë‹ˆë‹¤.</li>
                    </ul>
                    """
                }
                simplified_ai_text = '[ê¸°ëŠ¥ ì†Œê°œ í‘œì‹œ]'
            
            elif 'ì•ˆë…•' in user_message or 'hi' in user_message or 'hello' in user_message:
                ai_response = { 
                    'type': 'text', 
                    'content': 'ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? "í”„ë¡œì íŠ¸ ëª©ë¡"ì´ë‚˜ "ê¸°ìˆ  ìŠ¤íƒ"ì— ëŒ€í•´ ë¬¼ì–´ë³´ì‹œë©´ ì œê°€ ì•„ëŠ” ì •ë³´ë¥¼ ë³´ì—¬ë“œë¦´ê²Œìš”.',
                    'suggestions': ['í”„ë¡œì íŠ¸ ë³´ì—¬ì¤˜', 'ê¸°ìˆ  ìŠ¤íƒ ì•Œë ¤ì¤˜', 'ë¬´ì—‡ì„ í•  ìˆ˜ ìˆë‚˜ìš”?']
                }

            # Priority 4: Fallback to LLM with context
            if not ai_response:
                formatted_history = "\n".join([f"User: {h['user']}\nAssistant: {h['ai']}" for h in history])
                system_prompt = "You are a helpful AI assistant for a personal portfolio website. Your owner is a developer. Please answer the user's questions based on the persona of an assistant who knows the developer well. **You must always answer in Korean.**"
                prompt_text = f"{system_prompt}\n\n{formatted_history}\n\nUser: {user_message}\n\nAssistant (in Korean): "
                
                try:
                    ollama_api_url = "http://localhost:11434/api/generate"
                    payload = {"model": "llama3:instruct", "prompt": prompt_text, "stream": False, "options": {"temperature": 0.7}}
                    response = requests.post(ollama_api_url, json=payload, timeout=300)
                    response.raise_for_status()
                    ollama_response_data = response.json()
                    ollama_text_response = ollama_response_data.get('response', 'Ollamaì—ì„œ ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.')
                    ai_response = {'type': 'text', 'content': markdown.markdown(ollama_text_response)}
                except requests.exceptions.ConnectionError:
                    ai_response = {'type': 'text', 'content': 'Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}
                except requests.exceptions.RequestException as e:
                    ai_response = {'type': 'text', 'content': f'Ollama API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜: {e}'}

            # 4. Save new exchange to session history
            if not simplified_ai_text:
                simplified_ai_text = ai_response.get('content', '')

            history.append({'user': user_message, 'ai': simplified_ai_text})
            request.session['chat_history'] = history[-4:]

            return JsonResponse({'response': ai_response})

        except Exception as e:
            import traceback
            traceback.print_exc()
            return JsonResponse({'error': str(e)}, status=500)

    return JsonResponse({'error': 'Invalid request method'}, status=405)
